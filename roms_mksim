#! /usr/bin/env python3

"""Create script, batch and input files for ROMS simulations. Loadleveler and
SLURM batch files are supported but are specific to NIWA computers."""

# History (most recent first):
#
# MGH 2019-01-28
#   - To match a recent change in Rutgers ROMS, the default executable name is
#     now romsS, romsO or romsM. The job name, where applicable, is now ROMS.
# MGH 2018-10-24
#   - Arguments parsed with argparse instead of optparse
#   - SLURM scripts now adapted for the new NIWA HPCF system, Maui
#   - Now supports curly-bracket patterns, passed as commands to the shell,
#     in addition to angle-bracket patterns, evaluated by the Python
#     interpreter.
# MGH 2018-02-01
#   - Converted to python3
# MGH 2018-02-02
#   - Fixed several python3 porting bugs.
# MGH 2018-01-12
#   - Implemented SLURM scripts, so far only for MPI
# MGH 2018-01-12
#   - Implemented SLURM scripts for serial and OpenMP
#   - Removed Moab support
# MGH 2015-08-12
#   - For Loadleveler jobs, added network.MPI directive to run on Infiniband.
#   - Fixed up indentation problems caused by tab->space conversion.
# MGH 2014-06-30
#   - Default account now COBR1404.
# MGH 2013-06-19
#   - Changed MP_* environment variables set for MPI Loadleveler runs: removed
#     existing settings and added MP_TIMEOUT=300 to work around a delay in
#     setting up process on Fitzroy.
#   - Added calls to data before & after invoking ROMS in Loadleveler scripts.
#   - Names of script files changed to rom???.ll (Loadleveler), rom???.msub (Moab)
#     and rom???.sh (shell script).
# MGH 2012-10-17
#   - Removed jobid field from output log file name (but left it in output
#     err file name) for Fitzroy Loadleveler jobs.
#   - Default wall clock limit on Loadleveler jobs increased from 12 to 24
#     hours.
# MGH 2012-10-17
#   - Removed jobid field from output err file name for Fitzroy Loadleveler
#     jobs.
# MGH 2012-10-05
#   - LoadLeveler class option is now associated with the queue command-line
#     option (which is already used for Moab jobs).
# MGH 2012-10-04
#   - Changed default class for LoadLeveler jobs to General.
# MGH 2012-10-01
#   - Add account option to support the account_no Loadleveler keyword
#     on Fitzroy
# MGH 2012-09-13
#   - Corrected expression used to calculate n_node for Fitzroy MPI
#     jobs.
#   - Add jobid field in output file name for Fitzroy Loadleveler jobs.
# MGH 2011-11-25
#   - Removed "node_usage = not_shared" line from Loadleveler parallel
#     scripts.
# MGH 2010-10-20
#   - Added the ability to produce LoadLeveler scripts; removed
#     ability to produce Qsub scripts or Mosrun scripts.
# MGH 2010-04-3
#   - Moab MPI scripts further changed: the job is no longer
#     constrained to run on the minimum number of nodes.
# MGH 2010-03-02
#   - Moab MPI scripts revamped.
# MGH 2009-10-22
#   - The default location of the executable is now the current
#   working directory. The bldir function is no longer required and
#   has been deleted.
#   - Added support for Moab scripts.

import sys
import os
import re
import math
import argparse
import subprocess

p = re.compile('<<.*?>>')
q = re.compile('{{.*?}}')

def mkinput(index, tfile, ni, nj):
    infile = open(tfile,'r')
    outname = 'rom%3.3d.in'%(index)
    sys.stderr.write('Writing ROMS input file '+outname+'\n')
    outfile = open(outname, 'w')
    for line in infile.readlines():
        if not line.startswith("!"):
            # Search the line for matches to the angle-brackets regular
            # expression, evaluate the Python expression within and write the
            # results into the line
            nline = []
            s0 = (None,0)
            for m in p.finditer(line):
                s = m.span()
                nline.append(line[s0[1]:s[0]])
                exp = line[s[0]+2:s[1]-2]
                nline.append(str(eval(exp)))
                s0 = s
            nline.append(line[s0[1]:])
            line = ''.join(nline)
            # Search the line for matches to the curly-brackets regular
            # expression, run the command within and write the
            # results into the line
            nline = []
            s0 = (None,0)
            for m in q.finditer(line):
                s = m.span()
                nline.append(line[s0[1]:s[0]])
                cmd = line[s[0]+2:s[1]-2]
                nline.append(subprocess.check_output(cmd, shell=True)
                             .decode(sys.stdout.encoding).rstrip())
                s0 = s
            nline.append(line[s0[1]:])
            line = ''.join(nline)
        outfile.write(line)
    infile.close()
    outfile.close()

def mk_llsub(index, n_pro, resub, mpi, openmp, queue, acct, wall, exe):
    outname = 'rom%3.3d.ll'%(index)
    sys.stderr.write('Writing LoadLeveler script file %s\n'%(outname))
    outfile = open(outname, 'w')
    if mpi:
        # Some Fitzroy-specific code
        n_node = 1+(n_pro-1)//64
        if n_pro >= 32:
            usage = 'not_shared'
        else:
            usage = 'shared'
        outfile.write(
            '#! /bin/bash\n'
            '#@ job_name         = ROMS\n'
            '#@ output           = rom%3.3d.log\n'
            '#@ error            = rom%3.3d.err\n'
            '#@ job_type         = parallel\n'
            '#@ network.MPI      = sn_all,,US\n'
            '#@ class            = %s\n'
            '#@ account_no       = %s\n'
            '#@ total_tasks      = %d\n'
            '#@ task_affinity    = cpu(1)\n'
            '#@ node             = %d\n'
            '#@ notification     = never\n'
            '#@ wall_clock_limit = %s\n'
            '#@ node_usage       = %s\n'
            '#@ queue\n'
            '\n'
            'export MP_TIMEOUT=300\n'
            'date\n'
            'poe %s rom%3.3d.in\n'
            'date\n'
            %(index, index, queue, acct, n_pro, n_node, wall, usage, exe,
              index)
            )
    elif openmp:
        outfile.write(
            '#! /bin/bash\n'
            '#@ job_name         = ROMS\n'
            '#@ output           = rom%3.3d.log\n'
            '#@ error            = rom%3.3d.err\n'
            '#@ class            = %s\n'
            '#@ account_no       = %s\n'
            '#@ notification     = never\n'
            '#@ wall_clock_limit = %s\n'
            '#@ node_usage       = shared\n'
            '#@ queue\n'
            '\n'
            'export OMP_NUM_THREADS=%d\n'
            'date\n'
            '%s < rom%3.3d.in\n'
            'date\n'
            %(index, index, queue, acct, wall,n_pro, exe, index)
            )
    else:
        outfile.write(
            '#! /bin/bash\n'
            '#@ job_name         = ROMS\n'
            '#@ output           = rom%3.3d.log\n'
            '#@ error            = rom%3.3d.err\n'
            '#@ class            = %s\n'
            '#@ account_no       = %s\n'
            '#@ node_usage       = shared\n'
            '#@ notification     = never\n'
            '#@ wall_clock_limit = %s\n'
            '#@ queue\n'
            '\n'
            'date\n'
            '%s < rom%3.3d.in\n'
            'date\n'
            %(index, index, queue, acct, wall, exe, index)
            )
    if resub:
        outfile.write(
            'llsubmit rom%3.3d.ll\n'
            %(index+1)
            )
    outfile.close()

def mk_slurm(index, n_pro, resub, mpi, openmp, queue, acct, wall, exe):
    outname = 'rom%3.3d.sl'%(index)
    sys.stderr.write('Writing SLURM script file %s\n'%(outname))
    outfile = open(outname, 'w')
    if mpi:
        # Some code specific to the Maui General queue
        n_node = 1+(n_pro-1)//40
        if n_pro >= 40:
            usage = 'exclusive'
        else:
            usage = 'share'
        outfile.write(
            '#! /bin/bash\n'
            '#SBATCH --partition=nesi_research\n'
            '#SBATCH --job-name=ROMS\n'
            '#SBATCH --output=rom%3.3d.log\n'
            '#SBATCH --error=rom%3.3d.err\n'
            '#SBATCH --nodes=%d\n'
            '#SBATCH --ntasks=%d\n'
            '#SBATCH --time=%s\n'
            '#SBATCH --%s\n'
            '#SBATCH --hint=nomultithread\n'
            %(index, index, n_node, n_pro, wall, usage)
            )
        outfile.write(
            'date\n'
            'srun %s rom%3.3d.in\n'
            'date\n'
            %(exe, index)
            )
    elif openmp:
        outfile.write(
            '#! /bin/bash\n'
            '#SBATCH --partition=nesi_research\n'
            '#SBATCH --job-name=ROMS\n'
            '#SBATCH --output=rom%3.3d.log\n'
            '#SBATCH --error=rom%3.3d.err\n'
            '#SBATCH --nodes=1\n'
            '#SBATCH --ntasks=1\n'
            '#SBATCH --cpus-per-task=%d\n'
            '#SBATCH --time=%s\n'
            '#SBATCH --share\n'
            '#SBATCH --hint=nomultithread\n'
            %(index, index, n_pro, wall)
            )
        outfile.write(
            'export OMP_NUM_THREADS=%d\n'
            'date\n'
            '%s < rom%3.3d.in\n'
            'date\n'
            %(n_pro, exe, index)
            )
    else:
        outfile.write(
            '#! /bin/bash\n'
            '#SBATCH --partition=nesi_research\n'
            '#SBATCH --job-name=ROMS\n'
            '#SBATCH --output=rom%3.3d.log\n'
            '#SBATCH --error=rom%3.3d.err\n'
            '#SBATCH --nodes=1\n'
            '#SBATCH --ntasks=1\n'
            '#SBATCH --cpus-per-task=1\n'
            '#SBATCH --time=%s\n'
            '#SBATCH --share\n'
            '#SBATCH --hint=nomultithread\n'
            %(index, index, wall)
            )
        outfile.write(
            'date\n'
            '%s < rom%3.3d.in\n'
            'date\n'
            %(exe, index)
            )
    if resub:
        outfile.write(
            'sbatch rom%3.3d.sl\n'
            %(index+1)
            )
    outfile.close()

def mk_script(index, n_pro, resub, mpi, openmp, exe):
    outname = 'rom%3.3d.sh'%(index)
    sys.stderr.write('Writing script file '+outname+'\n')
    outfile = open(outname, 'w')
    outfile.write(
        '#! /bin/bash\n'
        '\n'
        'set -e\n'
        '\n'
        )
    if mpi:
        outfile.write(
            'nice mpirun -np %d %s rom%3.3d.in > rom%3.3d.log\n'
            %(n_pro,exe,index,index)
            )
    elif openmp:
        outfile.write(
            'export OMP_NUM_THREADS=%d\n'
            'nice %s < rom%3.3d.in > rom%3.3d.log\n'
            %(n_pro,exe,index,index)
            )
    else:
        outfile.write(
            'nice %s < rom%3.3d.in > rom%3.3d.log\n'
            %(exe,index,index)
            )
    if resub:
        outfile.write(
            'source rom%3.3d.sh\n'
            %(index+1)
            )
    outfile.close()
    os.chmod(outname,0o755)

def main():
    ap = argparse.ArgumentParser(description=__doc__,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    ap.add_argument("-e", "--executable",
        action="store", dest="exe", metavar="EXE",
        help="Location of ROMS executable")
    ap.add_argument("--min",
        action="store", type=int, dest="min", default=1, metavar="MIN",
        help="Minimum index (inclusive) for generated files")
    ap.add_argument("--max",
        action="store", type=int, dest="max", default=1, metavar="MAX",
        help="Maximum index (inclusive) for generated files")
    ap.add_argument("--ni",
        action="store", type=int, dest="ni", default=1, metavar="NI",
        help="Number of tiles in I direction")
    ap.add_argument("--nj",
        action="store", type=int, dest="nj", default=1, metavar="NJ",
        help="Number of tiles in J direction")
    ap.add_argument("-m", "--mpi",
        action="store_true", default=False,
        help="Run MPI executable")
    ap.add_argument("-o", "--openmp",
        action="store_true", default=False,
        help="Run OpenMP executable")
    ap.add_argument("--llsubmit", action="store_true", dest="llsub", default=False,
        help="Create LoadLeveler scripts for Fitzroy")
    ap.add_argument("--slurm",
        action="store_true", dest="slurm", default=False,
        help="Create SLURM scripts for Maui")
    ap.add_argument("-q", "--queue",
        action="store", dest="queue", metavar="QNAME",
        help="Queue name, where applicable")
    ap.add_argument("-a", "--account",
        action="store", dest="acct", metavar="ACCOUNT",
        help="Account ID, where applicable")
    ap.add_argument("-t", "--template",
        action="store", dest="tfile", default="roms.in", metavar="TFILE",
        help="ROMS input template file")
    ap.add_argument("-w", "--walltime",
        action="store", dest="wall", metavar="WALL",
        help="Wall clock time allocated for job, where applicable")
    args = ap.parse_args()
    if args.mpi and args.openmp:
        sys.exit('MPI and OpenMP modes cannot both be set')
    if not args.exe:
        if args.mpi:
            args.exe = "./romsM"
        elif args.openmp:
            args.exe = "./romsO"
        else:
            args.exe = "./romsS"
    try:
        for index in range(args.min,args.max+1):
            mkinput(index, args.tfile, args.ni, args.nj)
        for index in range(args.min,args.max+1):
            if args.llsub:
                if not args.queue:
                    args.queue = 'General'
                if not args.acct:
                    # Valid values are: COBR1404, CLCS1402
                    args.acct = 'COBR1404'
                if not args.wall:
                    # The default value should depend on the class: see llclass -l.
                    args.wall = '12:00:00'
                mk_llsub(index, args.ni*args.nj, index < args.max, args.mpi,
                         args.openmp, args.queue, args.acct, args.wall, args.exe)
            elif args.slurm:
                if not args.wall:
                    args.wall = '12:00:00'
                mk_slurm(index, args.ni*args.nj, index < args.max, args.mpi,
                          args.openmp, args.queue, args.acct, args.wall, args.exe)
            else:
                mk_script(index, args.ni*args.nj, index < args.max, args.mpi,
                          args.openmp, args.exe)
    except OSError as err:
        _, strerr = err.args
        sys.exit(strerr)

if __name__ == '__main__':
    main()
